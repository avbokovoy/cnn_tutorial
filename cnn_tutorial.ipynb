{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключаем необходимые библиотеки\n",
    "import os                                   # Модуль для работы с операционной системой\n",
    "    \n",
    "import torch                                # Основной модуль PyTorch \n",
    "import torch.nn as nn                       # Модуль PyTorch для работы с нейронными сетями\n",
    "import torch.utils.data as Data             # Модуль для работы с Dataset'ами\n",
    "\n",
    "import torchvision                          # Основной модуль PyTorch для работы с изображениями\n",
    "import torchvision.transforms as transforms # Модуль для преобразования изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f754c10e230>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)                        # Настраиваем генератор случайных чисел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель нейронной сети:\n",
    "class CNN( nn.Module ):\n",
    "    def __init__( self ):\n",
    "        super( CNN, self ).__init__()\n",
    "        self.conv1 = nn.Sequential(                   # Первый слой. На вход подается изображение с 3 каналами (RGB), \n",
    "                                                      # размером 32х32 или (3, 32, 32) \n",
    "            nn.Conv2d(                                # Функиця свертки.  \n",
    "                in_channels  = 3                      # Количество входящих каналов - 3, равно количеству каналов \n",
    "                                                      # изображения\n",
    "              , out_channels = 16                     # Количество исходящих каналов - 16\n",
    "              , kernel_size  = 5                      # Размер ядра свертки - 5\n",
    "              , stride       = 1                      # Смещение при свертке по горизонтали и вертикали - 1\n",
    "              , padding      = 2                      # Количество дополнительных столбцов и строк, заполненных нулями,\n",
    "                                                      # у границ изображения\n",
    "            )\n",
    "            , nn.ReLU()                               # Функция активации\n",
    "            , nn.MaxPool2d( kernel_size = 2 )         # Функция субдискретизации с размером ядра - 2\n",
    "        )                                             # На выходе - изображение ( 16, 16, 16 )  \n",
    "        \n",
    "        self.conv2 = nn.Sequential(                   # Второй слой. На входе изображение ( 16, 16, 16 )\n",
    "              nn.Conv2d( 16, 32, 5, 1, 2 )            # Функция свертки.\n",
    "            , nn.ReLU()                               # Функция активации.\n",
    "            , nn.MaxPool2d( 2 )                       # Функция субдискретизации. \n",
    "         )                                            # На выходе - изображение ( 32, 8, 8 )\n",
    "        \n",
    "        self.out = nn.Linear( 32 * 8 * 8, 10 )        # Персептрон. Первый аргумент - количество входящих пикселей.\n",
    "                                                      # Второй - размер полносвязного слоя (равен количеству классов, \n",
    "                                                      # на которые поделены изображения).\n",
    "\n",
    "    def forward( self, x ):                           # Переопределяем метод forward класса nn.Module\n",
    "        x = self.conv1(x)                             # Применяем первый слой.\n",
    "        x = self.conv2(x)                             # Применяем второй слой.\n",
    "        x = x.view( x.size(0), -1 )                   # 'Сплющиваем' до одномерного массива  \n",
    "        x = self.out(x)                               # Формируем перцептрон\n",
    "        return x                                      # Возвращаем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()                                           # Создаем объект типа CNN\n",
    "print(cnn)                                            # Выводим на экран архитектуру сети в текстовом виде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Скачиваем dataset Cifar10 https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(            \n",
    "      root      = './cifar10/'                        # Папка, в которую будут скачаны изображения, разметка и т.д.\n",
    "    , train     = True                                # Если True, данные будут созданы из тренировочного dataset'a\n",
    "                                                      # False - из тестировочного.\n",
    "    , transform = torchvision.transforms.ToTensor()   # Функция преобразования исходных данных в PyTorch Tensor.\n",
    "    , download  = True                                # Если True, то данные будут скачаны из удаленного репозитория, \n",
    "                                                      # False - будут использованы локальные данные\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(                       # Создаем объект типа Data.DataLoader\n",
    "      dataset    = train_data                         # Входящий dataset'a - train_data\n",
    "    , batch_size = 50                                 # Сколько изображений войдут в партию\n",
    "    , shuffle    = True                               # Нужно ли перемешивать изображения в dataset'e.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявляем оптимизатор (в конкретном случае - алгоритм Адама).\n",
    "# На входе - параметры сети и скорость обучения (learning rate)\n",
    "optimizer = torch.optim.Adam( cnn.parameters(), lr = 0.001 )  \n",
    "\n",
    "# Объявляем функцию потерь (в конкретном случае - функция кросс-энтропии)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,    99] loss: 1.261427\n",
      "[0,   199] loss: 1.253513\n",
      "[0,   299] loss: 1.252218\n",
      "[0,   399] loss: 1.211163\n",
      "[0,   499] loss: 1.208244\n",
      "[0,   599] loss: 1.177628\n",
      "[0,   699] loss: 1.173253\n",
      "[0,   799] loss: 1.182259\n"
     ]
    }
   ],
   "source": [
    "# Обучаем нейронную сеть\n",
    "\n",
    "MAX_EPOCH = 1                                             # Максимальное количество проходов по dataset'y\n",
    "\n",
    "running_loss = 0.0\n",
    "for epoch in range( MAX_EPOCH ):\n",
    "    for step, ( b_images, b_labels ) in enumerate( train_loader ):    # Для всех изображений b_images и разметок b_labels \n",
    "        output = cnn( b_images )                                      # Записываем результат работы сети в output\n",
    "        loss   = loss_func( output, b_labels )                        # Считаем ошибку между результатом output и заданной \n",
    "                                                                      # разметкой b_labels\n",
    "        optimizer.zero_grad()                                         # Обнуляем градиент\n",
    "        loss.backward()                                               # Используем метод обратного распространения ошибки\n",
    "        optimizer.step()                                              # Применяем градиент\n",
    "        \n",
    "        running_loss += loss.item()                                   # Получаем ошибку на текущем шаге\n",
    "        if step % 100 == 99:\n",
    "            print( '[%d, %5d] loss: %f' % ( epoch, step, running_loss / 100) )  # Выводим среднюю ошибку на экран\n",
    "            running_loss = 0.0                                                   # Обнуляем ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем dataset для тестирования\n",
    "\n",
    "# Объявляем необходимую для визуализаци функцию трансформации\n",
    "transform = transforms.Compose( [ \n",
    "        transforms.ToTensor()\n",
    "      , transforms.Normalize( ( 0.5,0.5, 0.5 ), ( 0.5, 0.5, 0.5 ) ) \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Скачиваем данные для тестирования работы нейронной сети по аналогии с train_data\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "      root = './cifar10/'\n",
    "    , train     = False\n",
    "    , download  = True\n",
    "    , transform = transform\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "      test_data\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , shuffle    = True\n",
    "    , num_workers = 2                      # Сколько процессов использоват для загрзки данных\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пишем вспомогательную функцию для визуализаци.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow( img ):\n",
    "    img   = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow( np.transpose( npimg, (1, 2, 0) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявляем вектор, содержащий названия всех классов изображений\n",
    "classes   = ( 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck' )\n",
    "# Объявляем итератор по всему тестовому dataset'y\n",
    "data_iter = iter( test_loader )\n",
    "# Считываем изображение и разметку.\n",
    "images, labels = data_iter.next()\n",
    "# Выводим изображение на экран\n",
    "imshow( torchvision.utils.make_grid( images ) ) \n",
    "# Выводим соответствующие классы\n",
    "print( 'GroundTruth: ', ' '.join( '%s' % classes[labels[j]] for j in range( BATCH_SIZE ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запускаем нейросеть на первых BATCH_SIZE изображениях из тестовой выборки\n",
    "outputs = cnn( images )\n",
    "_, predicted = torch.max( outputs, 1 )\n",
    "print( \"Predicted: \", ' '.join( '%s' % classes[predicted[j]] for j in range ( BATCH_SIZE ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишем функцию оценки точности работы получившейся сети\n",
    "\n",
    "class_correct = list( 0. for i in range(10) )                     # Выделим нулевой вектор размера 10 (количество классов)\n",
    "                                                                  # для весов корректно распознанных классов\n",
    "class_total   = list( 0. for i in range(10) )                     # -- || -- для общих весов классов\n",
    "with torch.no_grad():                                             # Указываем на то, что градиент не используется\n",
    "    for data in test_loader:                                      # Для всех изображений тестового dataset'a\n",
    "        images, labels = data                                     # Получаем текущие изображение и разметку\n",
    "        outputs = cnn( images )                                   # Применяем нейронную сеть к изображению\n",
    "        _, predicted = torch.max( outputs, 1 )                    \n",
    "        c = ( predicted == labels ).squeeze()\n",
    "        for i in range( BATCH_SIZE ):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label]   += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print( 'Accuracy of %s : %d %%' % (classes[i], 100 * class_correct[i] / class_total[i] ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
